![Icone](./images/logo/logo256x256.png "Icone")

# MLP - Implementação de Rede Neural Multicamadas (MLP) em Lua

Este repositório contém uma implementação independente de uma Rede Neural Multicamadas (MLP) em Lua, gerada com a ajuda de Inteligência Artificial. A rede foi implementada sem o uso de bibliotecas de aprendizado de máquina ou notação matricial. Ela pode ser configurada para suportar múltiplas camadas e unidades, sendo aplicada ao problema clássico do XOR.

## Visão Geral

O MLP é uma rede neural feedforward totalmente conectada com uma ou mais camadas ocultas. Este código usa a função de ativação sigmoide e implementa o algoritmo de retropropagação (backpropagation) para ajustar os pesos da rede durante o treinamento.

Esta implementação foi desenvolvida de forma independente para ser simples e didática, realizando os cálculos elemento a elemento (em vez de usar operações matriciais).

## Características

- Suporte para múltiplas camadas ocultas.
- Função de ativação sigmoide e sua derivada.
- Retropropagação (backpropagation) implementada para ajuste de pesos e vieses.
- Treinamento e teste para resolver o problema lógico do XOR.
- Não usa bibliotecas externas, tornando-o fácil de entender e modificar.
- Código gerado com a assistência de IA, mantendo total independência da implementação.

## Como Funciona

# Esse projeto foi uma reescrita em Lua de meu outro projeto em TypeScript:

- [WilliamJardim/MLP-Mini](https://github.com/WilliamJardim/MLP-mini) 
 A implantação da Rede Neural MLP em TypeScript.